{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gentle introduction to Pytorch Symbolic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You don't need any knowledge of the inner workings of Pytorch Symbolic to use it.\n",
    "In most cases, after seeing a few examples, you're good to go.\n",
    "If you used Keras Symbolic API before, you don't even need any learning materials.\n",
    "However, this notebooks explains Pytorch Symbolic a little bit deeper, in case you just want to know more stuff."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, we'll use our built-in drawing solution for layered graphs.\n",
    "Although it's not ideal, we hope it'll be just enough to demonstrate the concepts.\n",
    "\n",
    "You can use it yourself if you have an optional dependency are installed: `networkx`. It can be installed with `pip install networkx`.\n",
    "\n",
    "You can find the reference [in the Documentation](https://pytorch-symbolic.readthedocs.io/)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pytorch-symbolic torchvision networkx matplotlib scipy tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_symbolic import SymbolicModel, Input, useful_layers, graph_algorithms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Having fun with symbolic tensors\n",
    "### Simple example\n",
    "We'll first look at what we can do with symbolic tensors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = Input(shape=(5,))\n",
    "y = Input(shape=(5,))\n",
    "print(f\"x={x}\")\n",
    "print(f\"y={y}\")\n",
    "print()\n",
    "\n",
    "z = x + y\n",
    "print(\"After creating z = x + y:\")\n",
    "print(f\"x={x}\")\n",
    "print(f\"y={y}\")\n",
    "print(f\"z={z}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We created two symbolic tensors: `x` and `y`.\n",
    "Their sum is represented by another symbolic tensor: `z`, which was added to the graph of computations.\n",
    "\n",
    "When we print the tensors, we can see that `z` has two parents and both `x` and `y` have one child.\n",
    "\n",
    "If we need, we can even retrieve the instances of specific children and parents.\n",
    "\n",
    "As it is in life, you cannot change your parents, thus `.parents` are immutable. But `.children` are not!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"x.children={x.children}\")\n",
    "print(f\"y.children={y.children}\")\n",
    "\n",
    "print(f\"z.parents={z.parents}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are creating full fledged graphs now! Let's try to plot them..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To show you nicer plot, we prepared an option to show variable names in nodes of the graph.\n",
    "# It requires passing the namespace, e.g. globals().\n",
    "# By default, you'll see shape of the underlying Symbolic Tensor in each node.\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "graph_algorithms.draw_graph(inputs=(x, y), outputs=z, node_text_namespace=globals())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that addition was converted to `AddOpLayer`.\n",
    "\n",
    "If we want to use a custom operator or function on a symbolic tensor, we need to create an nn.Module.\n",
    "\n",
    "For simple operators like addition, Pytorch Symbolic will do it for us automatically!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A deeper example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will create another, more complicated model.\n",
    "\n",
    "Still no neural networks, but we'll get to them, I promise!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = Input(shape=())\n",
    "y = Input(shape=())\n",
    "\n",
    "sums = x + y\n",
    "diff = x - y\n",
    "mult = x * y\n",
    "intermediate_values = [sums, diff, mult]\n",
    "outputs = sum(intermediate_values) / 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intermediate_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the three intermediate values are children of 2 nodes and parent for 1 node."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "gr = graph_algorithms.draw_graph(inputs=(x, y), outputs=outputs, node_text_namespace=globals())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moreover, we see what Python does internally, when `sum` is called. It's just a bunch of additions! Obviously...\n",
    "\n",
    "Let us create a Symbolic Model from this graph!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SymbolicModel(inputs=(x, y), outputs=outputs)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rx = torch.rand(\n",
    "    1,\n",
    ")\n",
    "ry = torch.rand(\n",
    "    1,\n",
    ")\n",
    "\n",
    "print(f\"rx={rx}\")\n",
    "print(f\"ry={ry}\")\n",
    "print(f\"model(rx, ry)={model(rx, ry)}\")\n",
    "\n",
    "assert model(rx, ry) == ((rx + ry) + (rx - ry) + (rx * ry)) / 3, \"Something went wrong...\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we see, after defining the model on symbolic tensors, it works perfectly fine when launched on real data!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Right now, we were manipulating the data with `+`, `-` and `*` operators.\n",
    "\n",
    "Most of Python's operators are already defined for symbolic tensors, e.g.: `+, -, *, /, //, %, abs`.\n",
    "\n",
    "They will be converted to ``nn.Module`` and registered correctly in the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Symbolic tensors && real layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, in deep learning, we rarely use just standard operations. Instead, we rely on layers to transform the data.\n",
    "Let's create a small linear model with a few hidden layers!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = Input((4,))\n",
    "x1 = nn.Linear(inputs.features, 10)(inputs)\n",
    "x2 = nn.Linear(x1.features, 10)(x1)\n",
    "x3 = nn.Linear(x2.features, 10)(x2)\n",
    "outputs = nn.Linear(x3.features, 1)(x3)\n",
    "\n",
    "model = SymbolicModel(inputs, outputs)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like it was a succes. Let's see how it looks like as a graph!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6))\n",
    "graph_algorithms.draw_graph(model=model, node_text_namespace=globals())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's a rather simple topology."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### An odd one"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll now create a model that consists of a few towers - separate symbolic models.\n",
    "\n",
    "It means we will use symbolic model inside another symbolic model. Cool, isn't it?\n",
    "\n",
    "There'll be:\n",
    "* 3 separate inputs\n",
    "* 2 separate outputs\n",
    "\n",
    "After a few layers of separated computations, the results will be concatenated, then transformed some more and returned!\n",
    "\n",
    "On the drawing, we will see the shapes of Symbolic Tensors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_tower(height):\n",
    "    inputs = x = Input((5,))\n",
    "    for _ in range(height):\n",
    "        x = nn.Linear(x.features, 10)(x)\n",
    "    model = SymbolicModel(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "towers = [get_tower(height=3 + i) for i in range(3)]\n",
    "inputs = [Input((5,)) for _ in range(3)]\n",
    "tower_outputs = []\n",
    "\n",
    "for x, tower in zip(inputs, towers):\n",
    "    tower_outputs.append(tower(x))\n",
    "\n",
    "x = useful_layers.ConcatLayer(dim=1)(*tower_outputs)\n",
    "\n",
    "out1 = nn.Linear(x.features, 5)(x)\n",
    "out2 = nn.Linear(x.features, 3)(x)\n",
    "\n",
    "model = SymbolicModel(inputs, (out1, out2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "graph_algorithms.draw_graph(model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we want, we can even \"zoom in\" to the inner SymbolicModel. Let's try it:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6))\n",
    "graph_algorithms.draw_graph(model=towers[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This can be useful, if this model is complex and has many submodels!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Subgraphs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can operate on subgraphs too: we can either create models from them or just draw them.\n",
    "\n",
    "Let's use previous graph as an example.\n",
    "\n",
    "Let's say we want a new model that shares weights with the existing one.\n",
    "We want to omit the tower 1 and tower 3 computations, instead we'll provide their values \"by hand\" somehow."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input1 = tower_outputs[0]\n",
    "input2 = inputs[1]\n",
    "input3 = tower_outputs[2]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "graph_algorithms.draw_graph(inputs=(input1, input2, input3), outputs=(out1, out2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SymbolicModel(inputs=(input1, input2, input3), outputs=(out1, out2))\n",
    "print(model)\n",
    "\n",
    "real_outputs = model(torch.rand(1, 10), torch.rand(1, 5), torch.rand(1, 10))\n",
    "real_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Symbolic API in real models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us create and train a small ResNet example that will work on MNIST dataset.\n",
    "\n",
    "To train the model quickly, you need to have CUDA capable device.\n",
    "\n",
    "On Colab, be sure to set \"Hardware accelerator\" to \"GPU\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "\n",
    "ds = torchvision.datasets.MNIST(root=\".\", download=True, transform=torchvision.transforms.ToTensor())\n",
    "train, valid = torch.utils.data.random_split(ds, [50000, 10000])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train, batch_size=100, shuffle=True, drop_last=True, pin_memory=True, num_workers=1\n",
    ")\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid, batch_size=100, shuffle=False, drop_last=True, pin_memory=True, num_workers=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    def shortcut_func(x, channels, stride):\n",
    "        if x.channels != channels or stride != 1:\n",
    "            return x(nn.Conv2d(x.channels, channels, kernel_size=1, bias=False, stride=stride))\n",
    "        else:\n",
    "            return nn.Identity()(x)\n",
    "\n",
    "    inputs = Input(batch_shape=(100, 1, 28, 28))\n",
    "    flow = inputs(nn.Conv2d(inputs.channels, 16, 3, padding=1))\n",
    "\n",
    "    for group_size, width, stride in [(2, 16, 1), (2, 32, 2), (2, 64, 2)]:\n",
    "        for _ in range(group_size):\n",
    "            shortcut = shortcut_func(flow, width, stride)\n",
    "\n",
    "            flow = nn.BatchNorm2d(flow.channels)(flow)(nn.ReLU())\n",
    "            flow = nn.Conv2d(flow.channels, width, 3, stride, 1)(flow)\n",
    "            flow = nn.BatchNorm2d(flow.channels)(flow)(nn.ReLU())\n",
    "            flow = nn.Conv2d(flow.channels, width, 3, 1, 1)(flow)\n",
    "\n",
    "            flow = flow + shortcut\n",
    "            stride = 1\n",
    "\n",
    "    flow = nn.BatchNorm2d(flow.channels)(flow)(nn.ReLU())\n",
    "    flow = nn.MaxPool2d(kernel_size=flow.HW)(flow)(nn.Flatten())\n",
    "    outs = nn.Linear(flow.features, 10)(flow)\n",
    "    return inputs, outs\n",
    "\n",
    "\n",
    "inputs, outputs = create_model()\n",
    "model = SymbolicModel(inputs=inputs, outputs=outputs).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is a large model to draw! But let's try it anyway..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 5), constrained_layout=True)\n",
    "graph_algorithms.draw_graph(\n",
    "    model=model, edge_text_func=lambda x: \"\", node_text_namespace=globals(), rotate_graph=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def traininig(model, optimizer, epochs):\n",
    "    model.train()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        mean_acc = 0\n",
    "        mean_acc_n = 0\n",
    "\n",
    "        for x, y in train_dl:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "            outs = model(x)\n",
    "\n",
    "            loss = loss_fn(outs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = torch.mean((outs.argmax(1) == y).to(torch.float)).detach().cpu()\n",
    "            mean_acc += accuracy * x.shape[0]\n",
    "            mean_acc_n += x.shape[0]\n",
    "\n",
    "        print(f\"Average training accuracy in epoch {epoch + 1}: {mean_acc / mean_acc_n * 100 : <6.3f}%\")\n",
    "\n",
    "\n",
    "traininig(model, optimizer, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc = 0\n",
    "    mean_acc_n = 0\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_dl:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outs = model(x)\n",
    "            accuracy = torch.mean((outs.argmax(1) == y).to(torch.float)).detach().cpu()\n",
    "            mean_acc += accuracy\n",
    "            mean_acc_n += 1\n",
    "\n",
    "    print(f\"Average validation accuracy: {mean_acc / mean_acc_n * 100 : <6.3f}%\")\n",
    "\n",
    "\n",
    "evaluation(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Acceleration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hurray! We've trained a network that is pretty accurate. What else can we improve?\n",
    "\n",
    "Maybe performance? With Pytorch Symbolic you can enable CUDA Graphs using just one argument.\n",
    "\n",
    "This will work especially well for models with many small layers or where CPU calls are slower than GPU kernel execution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    inputs, outputs = create_model()\n",
    "    model = SymbolicModel(inputs=inputs, outputs=outputs, enable_cuda_graphs=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    traininig(model, optimizer, epochs=5)\n",
    "    evaluation(model)\n",
    "else:\n",
    "    print(\"CUDA Graphs require CUDA capable device!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Automatic code generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pytorch Symbolic also generates forward function code automatically. We are able too peek what was generated.\n",
    "\n",
    "We'll tweak one of the constants of code generator just for the sake of presentation:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_symbolic import config, add_to_model\n",
    "\n",
    "config.CODEGEN_MIN_LOOP_LENGTH = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will define the model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x1 = Input(shape=(3, 32, 32))\n",
    "\n",
    "x2 = nn.Conv2d(x1.C, 16, 3, padding=1)(x1)\n",
    "x3 = nn.Conv2d(x2.C, 16, 3, padding=1)(x2)\n",
    "x4 = nn.Conv2d(x3.C, 16, 3, padding=1)(x3)\n",
    "\n",
    "x11 = nn.Conv2d(x4.C, 16, 3, padding=1)(x4)\n",
    "x12 = nn.Conv2d(x11.C, 16, 3, padding=1)(x11)\n",
    "x13 = nn.Conv2d(x12.C, 16, 3, padding=1)(x12)\n",
    "x14 = nn.Conv2d(x13.C, 16, 3, padding=1)(x13)\n",
    "x15 = nn.Conv2d(x14.C, 16, 3, padding=1)(x14)\n",
    "\n",
    "x21 = nn.Conv2d(x4.C, 16, 3, padding=1)(x4)\n",
    "x22 = nn.Conv2d(x21.C, 16, 3, padding=1)(x21)\n",
    "x23 = nn.Conv2d(x22.C, 16, 3, padding=1)(x22)\n",
    "\n",
    "x5 = add_to_model(torch.concat, [x15, x23], dim=1)\n",
    "x6 = nn.Flatten()(x5)\n",
    "x7 = nn.Linear(x6.features, 1)(x6)\n",
    "\n",
    "model = SymbolicModel(inputs=x1, outputs=x7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(model._generated_forward_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 14), dpi=75)\n",
    "graph_algorithms.draw_graph(model=model, node_text_namespace=globals())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}